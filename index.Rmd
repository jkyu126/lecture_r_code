---
title: "R 데이터 분석 - 실전편"
author: "김진규"
output: 
  bookdown::html_document2:
  # html_document:
    toc: yes
    toc_float: yes
    toc_depth: 2
    collapsed: TRUE
    number_sections: TRUE
    fig_caption: TRUE
mainfont: NanumGothic
    
header-includes:
- \usepackage{booktabs}
#bibliography: [article.bib]
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,  warning = FALSE, message = FALSE,
  fig.show = 'hold', fig.align = 'center', fig.pos = 'h',  out.width = "80%"
)

pdf.options(family = "Korea1deb")

library(stringr)
library(dplyr)
library(ggplot2)
library(magrittr)
library(knitr)
library(kableExtra)
library(lubridate)
library(highcharter)
library(quantmod)
```


# 데이터 분석 실전편

- 사전 지식: R에 대한 기본적인 지식 (데이터 불러오기, 기본적인 계산)
- 논문 및 리포트 흐름: 여러 데이터 소스를 모으기 - **데이터 전처리 (병합, 계산 등)** - 분석 (Econometric tool) - 리포팅 (R Markdown 등)


## 접근법: 말을 배우는 것
- 말을 배울 때, 예를 들어 영어를 배울 때, 모든 영어 단어와 문법을 완벽히 숙지하고 처음 "Hello!"라는 말을 꺼내는 것은 말을 하는 데에 있어서는 상당히 비효율적인 접근법이라 생각함.
- 코딩도 마찬가지로 컴퓨터와 의사소통을 하는 것. 내가 원하는 것이 무엇인데, 이것을 컴퓨터가 알아들을 수 있도록 말해주는 것.
- 모든 명령어와 모든 코드를 알 필요가 없음. 오히려 자주 쓰이는 코드 및 코드의 논리를 몇가지만 알고, 이것을 편하게 제대로 사용하는 것이 효율적인 데이터 처리의 (말을 배우는 것의) 핵심. 

## 강의 목표
- 따라서 이번 강의에서는 데이터 전처리를 하는 데에 있어 **자주 쓰이는 말**을 공유. 
- 어떤 코드의 어떤 문법이 이해가 안된다고 너무 코드의 디테일에 집중하지 않으셔도 좋습니다.
- 코드를 보고 이게 어떤 역할을 하는 코드구나! 라고 파악하시고, 이를 응용해서 어떻게 사용하지? 라고 생각을 하시면 좋습니다. 
- 문법과 단어를 모두 이해하고 말을 시작하는 것이 아니라, 우선 자주 쓰이는 말을 배우고, 이게 무엇을 뜻하는지만 아시고 어떻게 사용할지를 고민해 보시는 것도 좋겠습니다.

## 강의 코드
- 강의에서 제공하는 코드는 제가 석사과정 논문을 작성하는 데에 사용한 데이터 처리과정 코드의 일부입니다.
- 코드와 데이터는 약간의 수정을 거쳤으며, 데이터는 샘플링을 통해 10% 미만의 데이터를 추출하였습니다.

## 코드 내용
- 여러 데이터 소스의 일별 데이터를 import하여 병합하는 단계
- 필터링
- 윈저라이즈 
- 윈저라이즈 한 변수와 원 데이터를 병합하는 단계 
- 일별 데이터를 월별 데이터로 만드는 단계
- Summary stat을 만드는 코드 (리포팅 코드 맛보기)

# 코드 

- Github의 제 코드 페이지 (https://github.com/jkyu126/lecture_r_code) 를 들어갑니다. 
- 우측 상단 Code 다운로드 버튼을 클릭합니다.
- 01_data_cleaning.R을 R로 열고 따라하시면 됩니다.


```{r eval=F, tidy=T}

rm(list=ls())
library(tidyverse)

########### STEP 1. IMPORT ALL DATASET ########### 
########### DATASETS ARE DAILY BASIS ###########

## 1. Import shareoutstanding data (Dataguide)

shrout = read.csv("./01_data/list/dataguide_shrout.csv", stringsAsFactors = F) %>%
  select(-Symbol) %>%
  tidyr::gather(Varname, Var, starts_with("A")) %>%
  mutate(stock2 = substr(Varname, 2,7), shrout = sapply(Var, function(x) gsub(",", "", x) %>% as.numeric())) %>%
  select(date_id, stock2, shrout) %>%
  arrange(stock2, date_id) %>% 
  drop_na() %>%
  as.data.frame()

## 2. Import price data (Dataguide)

price = read.csv("./01_data/list/dataguide_price.csv", stringsAsFactors = F)
for (i in 3:ncol(price)){
  price[,i] = sapply(price[,i], function(x) gsub(",", "", x))
  price[,i] = as.numeric(price[,i])
}
price2 = price %>% 
  tidyr::gather(stock, price, starts_with("A")) %>%
  mutate(stock2 = substr(stock, 2,7)) %>%
  select(-Symbol, -stock) %>%
  drop_na(price)

## 3. Import SAS calculated files
sas = read.csv("./01_data/summary.csv", stringsAsFactors = F) %>%
  mutate(stock2 = substr(ISU_CD,4,9), tradeday=1) %>%
  drop_na(mm)

## 4. Import Price Efficiency data
pe = read.csv("./01_data/pe_all.csv", stringsAsFactors = F) %>%
  drop_na(ISU_CD)




############ STEP 2. MERGE IMPORTED DATASETS #############

## 1. Merge Price + SAS

price_sas = price2 %>%
  left_join(sas, by=c("stock2", "date_id")) %>%
  group_by(stock2) %>%
  mutate(ret = (price - dplyr::lag(price))/dplyr::lag(price)) %>%
  filter(date_id != 122)

## 2. Merge PE and #1

price_sas_pe = price_sas %>%
  left_join(pe, by=c("ISU_CD", "date_id"))

## 3. Merge Shrout and #2

merged = price_sas_pe %>%
  left_join(shrout, by=c("stock2", "date_id")) %>%
  group_by(stock2) %>%
  mutate(amihud_p_bil = abs(ret*100)/(dvolume/1000000000),
         mktcap_bil = price*shrout/1000000000) %>%
  select(mm, date_id, ISU_CD, stock2, price, espread:adv_selection, ret, amihud_p_bil, mktcap_bil, sig.s, sig.p, PE, dg:Ksq) %>%
  as.data.frame()

############ STEP 3. FILTER DATASETS #############

filt2= merged %>% filter(nr_trades>10) 

############ STEP 4. WINSORIZE AT 1% #############

## 1. Generate percentile values and Winsorize at 1% 
## (price, espread, qspread, volume, dvolume, nr_trades, rspread, adv_selectin, ret, amihud_p_bil, mktcap_bil, total_tradeday)

wins1 = filt2 %>%
  select(stock2, date_id, price:mktcap_bil, sig.s, sig.p, PE) %>%
  tidyr::gather(Varname, Var, -(stock2:date_id)) %>%
  group_by(stock2, Varname) %>%
  mutate(perc = ntile(Var,100), perc99 = quantile(Var, 0.99, na.rm=T), perc1 = quantile(Var, 0.01, na.rm=T)) %>%
  mutate(adjVar = ifelse(perc==100, perc99, ifelse(perc==1, perc1, Var))) %>%
  as.data.frame()

## 2. Transformation: Long to Wide 

wins2 = wins1 %>% 
  select(stock2, date_id, Varname, adjVar) %>%
  tidyr::spread(Varname, adjVar)

## 3. Merge Winsorized data and dummy variables
wins3 = 
  wins2 %>% 
  left_join(filt2 %>% 
              select(date_id, stock2, mm, ISU_CD, dg, month, pre_mm, post_mm, post_mm2, prolong, Ksq), 
            by=c("stock2", "date_id")) %>%
  select(mm, stock2, date_id, espread, qspread, rspread, adv_selection, amihud_p_bil, volume, dvolume, price, ret, 
         nr_trades, mktcap_bil, sig.s, sig.p, PE, ISU_CD, dg, month, pre_mm, post_mm, post_mm2, prolong, Ksq ) %>%
  as.data.frame()



## 4. Merge MM fixed effects and #3

DF = wins3

## 5. Write CSV File
write.csv(DF, "./01_data/DF.csv", row.names = F)


############ STEP 5. GENERATE MONTHLY DATASET #############
rm(list=ls())

## 1. Generate Monthly dataset from Daily dataset
library(dplyr)
mydat = read.csv("./01_data/DF.csv", stringsAsFactors = F)
monthdat = 
  mydat %>%
  mutate(dg = ifelse(month==201603 & post_mm==1, dg+1, dg),
         month = ifelse(month==201603 & post_mm==1, month+1, month)) %>% #assign 20160328-20160331 to the next month (dg)
  arrange(stock2, dg, date_id) %>%
  group_by(stock2, dg) %>%
  summarise(mm = mean(mm),
            espread = mean(espread) * 100,
            qspread = mean(qspread) * 100, 
            rspread = mean(rspread) * 100,
            adv_selection = mean(adv_selection) * 100,
            amihud = mean(amihud_p_bil),
            volatility = sd(ret, na.rm=T) * 100,
            volume = mean(volume)/1000,
            dvolume = mean(dvolume)/1000000000,
            nr_trades = mean(nr_trades),
            price = mean(price)/1000,
            # autocorr = arima(ret, order=c(1,0,0))$coef["ar1"],
            ret = (exp(sum(log(1+ret)))-1)*100,
            mktcap = mean(mktcap_bil),
            sig.s = mean(sig.s, na.rm=T),
            sig.p = mean(sig.p, na.rm=T),
            PE = mean(PE, na.rm=T),
            month = mean(month),
            pre_mm = mean(pre_mm),
            post_mm = mean(post_mm), 
            post_mm2 = mean(post_mm2),
            prolong = mean(prolong),
            Ksq = mean(Ksq)
            ) %>% as.data.frame()
write.csv(monthdat, "./01_data/monthdat.csv", row.names=F)


## SUMMARY STAT
monthdat = read.csv("./01_data/monthdat.csv", stringsAsFactors = F)

t1 = monthdat %>%
  select(mm, espread:mktcap) %>% 
  tidyr::gather(Varname, Var, espread:mktcap)%>%
  group_by(mm, Varname) %>%
  summarise(Mean = mean(Var, na.rm=T), Std = sd(Var, na.rm=T), Min=min(Var, na.rm=T), Max=max(Var, na.rm=T), Median=median(Var, na.rm=T)) %>% 
  arrange(desc(mm), match(Varname, c("espread", "qspread", "rspread", "adv_selection", "amihud", "volatility", "volume", "dvolume",
                                     "price", "nr_trades", "ret", "mktcap"))) %>%
  ungroup() %>%
  select(-mm) %>%
  as.data.frame()

t1$Varname = rep(c("Effective Spread (%)", "Quoted Spread(%)", "Realized Spread(%)", "Adverse Selection(%)",
                   "ILLIQ (%/KRW 1M)", "Volatility(%)", "Volume (1,000 shares)", "Volume (KRW 1B)", "Price (KRW 1,000)",
                   "NumTrades", "Return (%)", "MktCap (KRW 1B)"),2)
colnames(t1)[1]=" "
t1[,2:6] = round(t1[,2:6], 3)

```






